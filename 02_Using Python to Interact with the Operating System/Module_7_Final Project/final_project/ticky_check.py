#!/usr/bin/python3

# Import Python modules
import re
import csv
import operator


# Initialize two dictionaries: 
# one for the number of different error messages 
# and another to count the number of entries for each user (splitting between INFO and ERROR).
per_error = {}
per_user = {}

#-------------------- The ranking of errors generated by the system --------------------#
pattern_error_msg = r"ticky: ERROR ([\w' ]*)"   # regex for ERROR message 

# Parse through each log entry in the syslog.log file by iterating over the file.
with open("syslog.log", "r", encoding="UTF-8") as file:
    for line in file:
        # match regex for each line
        error_msg = re.search(pattern_error_msg, line)
        # check that error_msg is not None and fill in dictionaries with error messages
        if error_msg:
            per_error[error_msg[1].rstrip()] = per_error.get(error_msg[1].rstrip(), 0) + 1

# Sort dictionary by the number of errors from most common to least common:
# sorted() function return list, operator.itemgetter(1) function sort tuple by second element
sorted_per_error = sorted(per_error.items(), key=operator.itemgetter(1), reverse=True)

# Initialize headers for the CSV report file
keys_field_error = ("Error", "Count")

# Create CSV report file with ERROR messages and numbering of each ERROR
with open("error_message.csv", "w", encoding="UTF-8") as file_csv:
    # create instance of the csv.writer class
    writer = csv.writer(file_csv)
    # write headers to the CSV report file
    writer.writerow(keys_field_error)
    # write errors to the CSV report file
    writer.writerows(sorted_per_error)


#-------------------- The user usage statistics for the service --------------------#
username_pattern = r"(\(.*\))$"         # regex for username
error_info_pattern = r"(ERROR|INFO)"    # regex for ERROR or INFO

# Parse through each log entry in the syslog.log file by iterating over the file.
with open("syslog.log", "r", encoding="UTF-8") as file:
    for line in file:
        # parse the username
        username = re.search(username_pattern, line).group(0)[1:-1]
        # parse the ERROR or INFO
        error_info = re.search(error_info_pattern, line).group(0)
        # For each log entry, you'll have to first check if it matches the INFO or ERROR message formats.
        # You should use regular expressions for this.
		# When you get a successful match, add one to the corresponding value in the per_user dictionary.
        if error_info == "INFO":
            per_user[username] = per_user.get(username, {error_info: 0, "ERROR": 0})
            per_user[username][error_info] += 1
        if error_info == "ERROR":
            per_user[username] = per_user.get(username, {"INFO": 0, error_info: 0})
            per_user[username][error_info] += 1

# Sort dictionary by the username:
# sorted() function return list, operator.itemgetter(0) function sort tuple by first element
sorted_per_user = sorted(per_user.items(), key=operator.itemgetter(0))

# Initialize headers for the CSV report file
keys_field_user = ("Username", "INFO", "ERROR")

# Create CSV report file with user usage statistics for the serviceOR
with open("user_statistics.csv", "w", encoding="UTF-8") as file_csv:
    # write headers to the CSV report file
    file_csv.write(f"{keys_field_user[0]}, {keys_field_user[1]}, {keys_field_user[2]}\n")
    # write usage statistics to the CSV report file
    for line in sorted_per_user:
        file_csv.write(f"{line[0]}, {line[1].get('INFO')}, {line[1].get('ERROR')}\n")